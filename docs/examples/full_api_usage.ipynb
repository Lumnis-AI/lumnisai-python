{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Users:\n",
      "     kevin@ksylvest.com\n",
      "     ari@sisu.site\n",
      "     amboufaye1@gmail.com\n",
      "     vyahhi@gmail.com\n",
      "     ajaye2@illinois.edu\n",
      "     abubakarr_jaye@alumni.brown.edu\n",
      "     lumnistrading@gmail.com\n",
      "     moribajaye@gmail.com\n",
      "     abujaye@gmail.com\n",
      "     alice@test-acme.one\n",
      "     abu.jaye@gmail.com\n",
      "     hamza@test-acme.one\n",
      "==================================================\n",
      "Existing API keys:\n",
      "     EXA_API_KEY Exists - Created at 2025-06-20T02:50:30.419402+00:00\n",
      "     OPENAI_API_KEY Exists - Created at 2025-06-20T02:50:25.676567+00:00\n",
      "==================================================\n",
      "Model Preferences (Tenant: fa12c8b3-6f5d-434c-9797-fdbe8c1f6915):\n",
      "  CHEAP_MODEL: openai:gpt-4.1-nano ✓\n",
      "  FAST_MODEL: openai:gpt-4.1-mini ✓\n",
      "  SMART_MODEL: openai:gpt-4.1 ✓\n",
      "  REASONING_MODEL: openai:o3-mini ✓\n",
      "  VISION_MODEL: openai:gpt-4o ✓\n",
      "\n",
      "Defaults applied for: CHEAP_MODEL\n",
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "import lumnisai\n",
    "from lumnisai import Scope, ApiProvider, AsyncClient\n",
    "from IPython.display import Markdown\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Optional\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from lumnisai.types import ModelType\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def display_markdown(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "# Create client\n",
    "lumnisai_agent = lumnisai.AsyncClient()\n",
    "\n",
    "# List users\n",
    "users = await lumnisai_agent.list_users(page_size=50)\n",
    "\n",
    "# Check if alice@test-acme.one exists in users\n",
    "alice_user = next((user for user in users.users if user.email == \"alice@test-acme.one\"), None)\n",
    "\n",
    "# Create user if not found\n",
    "if alice_user is None:\n",
    "    user = await lumnisai_agent.create_user( email=\"alice@test-acme.one\", first_name=\"Alice\", last_name=\"Doe\" )\n",
    "\n",
    "# Print users\n",
    "print(\"Existing Users:\")\n",
    "for user in users.users:\n",
    "    print(\"    \", user.email)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# List API keys\n",
    "api_keys = await lumnisai_agent.list_api_keys()\n",
    "print(\"Existing API keys:\")\n",
    "for api_key in api_keys:\n",
    "    print(\"    \", api_key.provider, \"Exists - Created at\", api_key.created_at)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add API keys\n",
    "await lumnisai_agent.add_api_key(ApiProvider.OPENAI_API_KEY, os.getenv(\"OPENAI_API_KEY\"))\n",
    "await lumnisai_agent.add_api_key(ApiProvider.EXA_API_KEY, os.getenv(\"EXA_API_KEY\"))\n",
    "\n",
    "preferences = await lumnisai_agent.get_model_preferences()\n",
    "print(preferences)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Preferences (Tenant: fa12c8b3-6f5d-434c-9797-fdbe8c1f6915):\n",
      "  CHEAP_MODEL: openai:gpt-4.1-nano ✓\n",
      "  FAST_MODEL: openai:gpt-4.1-mini ✓\n",
      "  SMART_MODEL: openai:gpt-4.1 ✓\n",
      "  REASONING_MODEL: openai:o3-mini ✓\n",
      "  VISION_MODEL: openai:gpt-4o ✓\n",
      "\n",
      "Defaults applied for: CHEAP_MODEL\n"
     ]
    }
   ],
   "source": [
    "new_preferences = {\n",
    "    \"FAST_MODEL\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4.1-mini\"\n",
    "    },\n",
    "    \"SMART_MODEL\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4.1\"\n",
    "    },\n",
    "    \"REASONING_MODEL\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"o3-mini\"\n",
    "    }\n",
    "}\n",
    "\n",
    "updated = await lumnisai_agent.update_model_preferences(new_preferences)\n",
    "print(updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_email = \"abu.jaye@gmail.com\" # \"alice@test-acme.one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all the apps that are available to you:\n",
      "App Status:\n",
      "  Enabled Apps (3): GITHUB, GMAIL, SLACK\n",
      "  Available Apps (144): BRIGHTPEARL, SLACKBOT, YANDEX, SALESFORCE, ATTIO, SUPABASE, AIRTABLE, LEVER, TWITCH, FIGMA, TODOIST, CLOCKIFY, TWITTER, GITLAB, BORNEO, WRIKE, BRAINTREE, BREX_STAGING, ZOHO_INVENTORY, FITBIT, RIPPLING, SURVEY_MONKEY, D2LBRIGHTSPACE, GO_TO_WEBINAR, INTERCOM, CONFLUENCE, LEVER_SANDBOX, BITBUCKET, ASANA, GOOGLEADS, SEISMIC, CANVAS, SHOPIFY, TIMECAMP, CLOSE, CHATWORK, JIRA, SQUARE, ACCELO, CANVA, FACEBOOK, GOOGLESHEETS, ZOHO, REDDIT, KOMMO, GITHUB, BOX, ALGOLIA, ZOHO_INVOICE, BREVO, CLICKUP, MURAL, ZOOM, BOLDSIGN, ZOHO_MAIL, BATTLENET, HUBSPOT, GOOGLETASKS, GOOGLE_MAPS, RAMP, TRELLO, GUMROAD, AMAZON, DROPBOX, MAILCHIMP, METAADS, BREX, LODGIFY, DYNAMICS365, GOOGLESLIDES, LINKEDIN, BLACKBAUD, TONEDEN, WAKATIME, CONTENTFUL, WAVE_ACCOUNTING, KEAP, ZOHO_BIGIN, CALENDLY, ICIMS_TALENT_CLOUD, SLACK, PIPEDRIVE, SPLITWISE, XERO, GOOGLE_ANALYTICS, NETSUITE, EXCEL, OUTLOOK, INSIGHTO_AI, GOOGLEDOCS, LINKHUT, TALLY, GORGIAS, ZENDESK, MICROSOFT_TEAMS, ZOHO_DESK, HARVEST, FRESHBOOKS, DEEL, SHARE_POINT, STACK_EXCHANGE, KLAVIYO, YOUTUBE, BEEMINDER, QUICKBOOKS, OMNISEND, YNAB, GOOGLEDRIVE, GOOGLEPHOTOS, MONDAY, SAGE, SERVICEM8, DIALPAD, MICROSOFT_TENANT, AUTH0, APALEO, EPIC_GAMES, DISCORD, ATLASSIAN, DOCUSIGN, HIGHLEVEL, GOOGLECALENDAR, DISCORDBOT, EVENTBRITE, GOOGLESUPER, ZOHO_BOOKS, PRODUCTBOARD, PAGERDUTY, GOOGLEMEET, MIRO, RING_CENTRAL, BLACKBOARD, DROPBOX_SIGN, WEBEX, NOTION, WIZ, TWITTER_MEDIA, TIMELY, SMARTRECRUITERS, ONE_DRIVE, LINEAR, LASTPASS, GMAIL, EXIST\n",
      "==================================================\n",
      "   github is already enabled.\n",
      "   gmail is already enabled.\n",
      "Checking github...\n",
      "Checking gmail...\n",
      "Checking github...\n",
      "   App: GITHUB\n",
      "   Status: active\n",
      "   Connected at: 2025-07-02 00:08:03.948789\n",
      "Checking gmail...\n",
      "   App: GMAIL\n",
      "   Status: active\n",
      "   Connected at: 2025-07-03 21:54:39.264666\n"
     ]
    }
   ],
   "source": [
    "# List apps\n",
    "apps = await lumnisai_agent.list_apps(include_available=True)\n",
    "print(\"These are all the apps that are available to you:\")\n",
    "print(apps)\n",
    "\n",
    "# Enable apps to tenant if not enabled\n",
    "print(\"=\"*50)\n",
    "apps_to_connect = [\"github\", \"gmail\", ]#'googledocs' \n",
    "for app in apps_to_connect:\n",
    "    if not await lumnisai_agent.is_app_enabled(app):\n",
    "        print(f\"   {app} is not enabled. Enabling it now...\")\n",
    "        result = await lumnisai_agent.set_app_enabled(app, enabled=True)\n",
    "    else:\n",
    "        print(f\"   {app} is already enabled.\")\n",
    "\n",
    "\n",
    "for app in apps_to_connect:\n",
    "    print(f\"Checking {app}...\")\n",
    "    if await lumnisai_agent.is_app_enabled(app):\n",
    "        status = await lumnisai_agent.get_connection_status( user_id=user_email, app_name=app)\n",
    "        if status.status != \"active\":\n",
    "            print(f\"   {app} is enabled. Connecting to it now...\")\n",
    "            connection = await lumnisai_agent.initiate_connection( user_id=user_email, app_name=app)\n",
    "            print(\"Sign in using the following URL to connect to the app: \", connection)\n",
    "\n",
    "for app in apps_to_connect:\n",
    "    print(f\"Checking {app}...\")\n",
    "    status = await lumnisai_agent.get_connection_status(user_id=user_email, app_name=app)\n",
    "    print(f\"   App: {status.app_name}\")\n",
    "    print(f\"   Status: {status.status}\")\n",
    "    if status.connected_at:\n",
    "        print(f\"   Connected at: {status.connected_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "User Connections (User ID: abu.jaye@gmail.com):\n",
      "  GMAIL: active (connected: 2025-07-03 21:54:39.264666)\n",
      "  GITHUB: active (connected: 2025-07-02 00:08:03.948789)\n",
      "\n",
      "Total connections: 2\n",
      "==================================================\n",
      "Available Tools (User ID: abu.jaye@gmail.com):\n",
      "  GMAIL:\n",
      "    • GMAIL_DELETE_DRAFT: Permanently deletes a specific gmail draft using its id; ensure the draft exists and the user has necessary permissions for the given `user id`.\n",
      "    • GMAIL_DELETE_MESSAGE: Permanently deletes a specific email message by its id from a gmail mailbox; for `user id`, use 'me' for the authenticated user or an email address to which the authenticated user has delegated access.\n",
      "    • GMAIL_FETCH_EMAILS: Fetches a list of email messages from a gmail account, supporting filtering, pagination, and optional full content retrieval.\n",
      "    • GMAIL_FETCH_MESSAGE_BY_MESSAGE_ID: Fetches a specific email message by its id, provided the `message id` exists and is accessible to the authenticated `user id`.\n",
      "    • GMAIL_GET_ATTACHMENT: Retrieves a specific attachment by id from a message in a user's gmail mailbox, requiring valid message and attachment ids.\n",
      "    • GMAIL_GET_CONTACTS: Fetches contacts (connections) for the authenticated google account, allowing selection of specific data fields and pagination.\n",
      "    • GMAIL_LIST_DRAFTS: Retrieves a paginated list of email drafts from a user's gmail account. use verbose=true to get full draft details including subject, body, sender, and timestamp.\n",
      "    • GMAIL_MOVE_TO_TRASH: Moves an existing, non-deleted email message to the trash for the specified user.\n",
      "    • GMAIL_PATCH_LABEL: Patches the specified label.\n",
      "    • GMAIL_REPLY_TO_THREAD: Sends a reply within a specific gmail thread using the original thread's subject, requiring a valid `thread id` and correctly formatted email addresses.\n",
      "    • GMAIL_SEARCH_PEOPLE: Searches contacts by matching the query against names, nicknames, emails, phone numbers, and organizations, optionally including 'other contacts'.\n",
      "    • GMAIL_SEND_DRAFT: Sends the specified, existing draft to the recipients in the to, cc, and bcc headers.\n",
      "    • GMAIL_SEND_EMAIL: Sends an email via gmail api using the authenticated user's google profile display name, requiring `is html=true` if the body contains html and valid `s3key`, `mimetype`, `name` for any attachment.\n",
      "  GITHUB:\n",
      "    • GITHUB_CREATE_AN_ISSUE: Creates a new issue in a github repository, requiring the repository to exist and have issues enabled; specific fields like assignees, milestone, or labels may require push access.\n",
      "    • GITHUB_CREATE_A_PULL_REQUEST: Creates a pull request in a github repository, requiring existing `base` and `head` branches; `title` or `issue` must be provided.\n",
      "    • GITHUB_GET_A_PULL_REQUEST: Retrieves a specific pull request from a github repository using its owner, repository name, and pull request number.\n",
      "    • GITHUB_LIST_BRANCHES: Lists branches for an existing github repository, with an option to filter by protection status.\n",
      "    • GITHUB_LIST_COMMITS: Retrieves commits for a repository, optionally filtering by sha (must be valid commit sha or existing branch), path, author, committer, or date range.\n",
      "    • GITHUB_LIST_PULL_REQUESTS: Lists pull requests for a specified github repository.\n",
      "    • GITHUB_LIST_REPOSITORY_ISSUES: Lists issues (which include pull requests) for a specified, existing github repository, with options for filtering, sorting, and pagination.\n",
      "    • GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER: Stars an existing and accessible repository for the authenticated user; this action is idempotent and succeeds even if the repository is already starred.\n",
      "\n",
      "Total tools: 21\n"
     ]
    }
   ],
   "source": [
    "# List connections\n",
    "print(\"=\"*50)\n",
    "connections = await lumnisai_agent.list_connections(user_email)\n",
    "print(connections)\n",
    "\n",
    "# List tools\n",
    "print(\"=\"*50)\n",
    "tools = await lumnisai_agent.get_integration_tools(user_email)\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 6eee8134-6f81-4017-836a-94de2a7005f2\n",
      "PROCESSING - Agent thinking...\n",
      "PROCESSING - Researching and summarizing the most recent (2025) trends in AI agents and machine learning.\n",
      "PROCESSING - Explaining what 'agentic models' are, key characteristics, and how they differ from traditional models.\n",
      "PROCESSING - Compiling a list of the most recent (2024-2025) research papers on agentic models and agentic AI, with links, abstracts, and publication dates.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Streaming response  \n",
    "async for update in await lumnisai_agent.invoke(\"\"\" \n",
    "                                                What are the latest trends in AI agents and machine learning? \n",
    "                                                What are agentic models? \n",
    "                                                What are the latest papers on agentic models and agentic AI?. \n",
    "                                                \"\"\", stream=True, user_id=user_email):\n",
    "    print(f\"{update.state.upper()} - {update.message}\")\n",
    "\n",
    "display(Markdown(update.output_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 536f5f5c-aeed-4469-80ca-e8d0ac30a218\n",
      "Museum: Louvre Museum\n",
      "Location: Paris, France\n",
      "{\n",
      "    \"name\": \"Louvre Museum\",\n",
      "    \"address\": {\n",
      "        \"city\": \"Paris\",\n",
      "        \"street\": \"Rue de Rivoli\",\n",
      "        \"country\": \"France\",\n",
      "        \"postal_code\": \"75001\"\n",
      "    },\n",
      "    \"category\": \"Art Museum\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example demonstrating how to use structured output with the Lumnis SDK.\n",
    "\n",
    "The SDK supports two ways to specify response format:\n",
    "1. Pass a Pydantic model class directly (recommended)\n",
    "2. Pass a JSON Schema dictionary\n",
    "\"\"\"\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: Optional[str] = None\n",
    "\n",
    "class BusinessInfo(BaseModel):\n",
    "    name: str = Field(description=\"Business name\")\n",
    "    category: str = Field(description=\"Type of business\")\n",
    "    address: Address\n",
    "    phone: Optional[str] = None\n",
    "    website: Optional[str] = None\n",
    "    rating: Optional[float] = Field(None, ge=0, le=5)\n",
    "\n",
    "\n",
    "# Example: Complex structure with nested models\n",
    "response_structured = await lumnisai_agent.invoke(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me about the Louvre Museum\"}],\n",
    "    response_format=BusinessInfo,  # Pass the model class directly\n",
    "    response_format_instructions=\"Include all available details\",\n",
    "    user_id=user_email\n",
    ")\n",
    "\n",
    "if response_structured.structured_response:\n",
    "    museum = BusinessInfo(**response_structured.structured_response)\n",
    "    print(f\"Museum: {museum.name}\")\n",
    "    print(f\"Location: {museum.address.city}, {museum.address.country}\")\n",
    "\n",
    "    print(json.dumps(response_structured.structured_response, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ProgressEntry(ts=datetime.datetime(2025, 7, 4, 0, 4, 14, 23458, tzinfo=TzInfo(UTC)), state='processing', message='Starting agent...', output_text=None),\n",
       " ProgressEntry(ts=datetime.datetime(2025, 7, 4, 0, 4, 28, 436610, tzinfo=TzInfo(UTC)), state='completed', message='Response completed successfully.', output_text=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_structured.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 766f5d48-2f80-4de5-a687-f53e36b3ff3d\n",
      "PROCESSING: Starting agent...\n",
      "PROCESSING: Searching for the most recent (2024-2025) developments, publications, and news on AI agents.\n",
      "PROCESSING: Searching for the most recent (2024-2025) developments, publications, and news on machine learning.\n",
      "PROCESSING: Synthesizing and analyzing the latest (2024–2025) trends in AI agents, highlighting architectures, benchmarks, applications, and breakthroughs.\n",
      "PROCESSING: Synthesizing and analyzing the latest (2024–2025) trends in machine learning, focusing on algorithms, frameworks, applications, and breakthroughs.\n",
      "PROCESSING: Combining the analysis of 2024–2025 trends in AI agents and machine learning into a clear, structured, well-organized report with non-overlapping coverage.\n",
      "PROCESSING: Carefully review the unified report on latest trends in AI agents and machine learning for completeness, accuracy, and clarity, revising sections if needed.\n",
      "PROCESSING: Send the requester the final, reviewed report summarizing the most significant 2024–2025 trends in AI agents and machine learning.\n",
      "COMPLETED: Response completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Latest Trends in AI Agents and Machine Learning (2024–2025)\n",
       "\n",
       "---\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "From early 2024 through mid-2025, artificial intelligence has advanced dramatically in both agent-based systems and foundational machine learning (ML). AI agents have become sophisticated, modular, and context-aware, driving automation and new capabilities across industries. Machine learning breakthroughs underpin these agents with robust, efficient algorithms, transformative architectures, and new training paradigms. Below is a clear synthesis of the non-overlapping developments and key trends in both domains.\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Advances in AI Agents\n",
       "\n",
       "### 1.1 New Architectures and Capabilities\n",
       "\n",
       "- **LLMs as Agentic Cores:**  \n",
       "  Models like GPT-4/5, PaLM, and Bedrock now power reasoning, planning, and multi-turn dialogue in modern agents.  \n",
       "  [IEEE Computer Society](https://www.computer.org/publications/tech-news/community-voices/autonomous-ai-agents)\n",
       "\n",
       "- **Memory-Augmented and Contextual Agents:**  \n",
       "  Agents routinely use long-term and episodic memory, supporting richer context, autonomy, and adaptation.  \n",
       "  [Arxiv](https://arxiv.org/abs/2501.11739)\n",
       "\n",
       "- **Multi-Agent and Decentralized Systems:**  \n",
       "  Teams (\"swarms\") of agents, often decentralized, now tackle complex real-world challenges together.  \n",
       "  [Forbes](https://www.forbes.com/sites/solrashidi/2025/02/28/the-5-ai-trends-in-2025-agents-open-source-and-multi-model/)\n",
       "\n",
       "- **Tool Use and Retrieval-Augmented Generation (RAG):**  \n",
       "  Agents autonomously leverage APIs, databases, and internet search—blending traditional software engineering and generative reasoning.  \n",
       "  [LinkedIn](https://www.linkedin.com/pulse/inside-ai-agents-how-perceive-decide-act-learn-artemakis-artemiou-1nzrf)\n",
       "\n",
       "- **Multimodal and Edge-Integrated Agents:**  \n",
       "  New agents process voice, images, video, and sensor data—using both on-device and cloud resources for scalability.  \n",
       "  [ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2949953425000141)\n",
       "\n",
       "---\n",
       "\n",
       "### 1.2 Benchmarks and Evaluation\n",
       "\n",
       "- Evaluation now emphasizes long-horizon planning, human–agent collaboration, and memory retention.\n",
       "- Productivity, satisfaction, and ethical dimensions are increasingly key metrics.  \n",
       "  [Arxiv](https://arxiv.org/abs/2501.11739)\n",
       "\n",
       "---\n",
       "\n",
       "### 1.3 Notable Applications\n",
       "\n",
       "- **Enterprise Automation:** Document parsing, analytics, workflow orchestration, and support.\n",
       "- **Healthcare:** Diagnostics, triage, and care simulation.\n",
       "- **Finance & Smart Cities:** Risk modeling, accessibility, urban/logistics management.\n",
       "- **Personal Productivity:** Context-aware assistants for scheduling and information.\n",
       "\n",
       "---\n",
       "\n",
       "### 1.4 Breakthroughs and Industry Trends\n",
       "\n",
       "- **Open Source Agent Frameworks:** LangChain, AutoGPT, and Copilot Studio speed agent creation.\n",
       "- **Custom/Plug-and-Play Agents:** Industry is rapidly adopting tailored, domain-specific agents.\n",
       "- **Responsible AI & Memory Regulation:** Safe, explainable, and privacy-conscious design is central.\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Advances in Machine Learning\n",
       "\n",
       "### 2.1 New Algorithms and Core Breakthroughs\n",
       "\n",
       "- **Segment Anything Model 2 (SAM 2):** Real-time video tracking extends from static images to many domains.  \n",
       "  [MachineLearningMastery.com](https://machinelearningmastery.com/5-breakthrough-machine-learning-research-papers-already-in-2025/)\n",
       "\n",
       "- **Speculative Cascades:** Cascading between fast and complex models improves inference efficiency.\n",
       "\n",
       "- **Data Shapley/Attribution:** Efficiently values each training sample, streamlining data quality and compliance.\n",
       "\n",
       "- **Transformers’ Robustness:** Theoretical advances now clarify why transformers generalize reliably.\n",
       "\n",
       "- **Continual & Real-Time Learning:** New models like StreamLearn 2.0 adapt on-the-fly for evolving data.\n",
       "\n",
       "---\n",
       "\n",
       "### 2.2 Frameworks and Infrastructural Shifts\n",
       "\n",
       "- **Neuromorphic Hardware & CRAM:** Neuro-inspired chips and in-memory computing enable up to 1,000× energy efficiency.  \n",
       "  [ScienceDaily](https://www.sciencedaily.com/releases/2024/07/240726113337.htm)\n",
       "\n",
       "- **Small Language Models (SLMs):** Compact (1–10B param) open models democratize LLMs for edge/mobile use.  \n",
       "  [Medium](https://medium.com/@taiwo.omotayo/the-cutting-edge-of-machine-learning-whats-new-in-2025-b12fc61dc862)\n",
       "\n",
       "- **Causal Inference & Explainability:** Widespread adoption of causal methods increases fairness and transparency.\n",
       "\n",
       "- **Federated & Privacy-Preserving Learning:** Models learn locally, keeping data private—critical for healthcare/IoT.\n",
       "\n",
       "---\n",
       "\n",
       "### 2.3 Emerging Trends\n",
       "\n",
       "- **Meta-Learning & Extrapolation:** E2T and meta-learning enable robust generalization for rare/unseen scenarios.  \n",
       "  [Phys.org](https://phys.org/news/2025-04-ai-extrapolative-master-materials.html)\n",
       "\n",
       "- **Human-in-the-Loop Training:** Real-time, interactive feedback (GUIDE framework) is closing the gap to dynamic learning.  \n",
       "  [ScienceDaily](https://www.sciencedaily.com/releases/2024/12/241203154556.htm)\n",
       "\n",
       "- **Quantum Machine Learning:** Quantum compilation algorithms now speed up scientific simulation.  \n",
       "  [ScienceDaily](https://www.sciencedaily.com/releases/2024/12/241210115620.htm)\n",
       "\n",
       "- **Brain-like Machine Vision:** Architectures such as Lp-Convolution improve adaptability in AI vision.\n",
       "\n",
       "---\n",
       "\n",
       "### 2.4 Real-World Applications\n",
       "\n",
       "- **Robotics:** RL enables flexible, learning robots across tasks and settings.\n",
       "- **Weather Modeling:** ML delivers 15-day forecasts as accurate as old 7-day predictions.\n",
       "- **Scientific Discovery & Mathematics:** AI assists proofs, simulation, and research.\n",
       "- **Healthcare:** Synthetic data, privacy, and advanced segmentation shift diagnostics.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Synthesis and Distinction\n",
       "\n",
       "- **AI agents** operationalize memory, collaboration, autonomous action, and tool-based problem-solving.\n",
       "- **Machine learning** advances provide the robust, efficient, interpretable, and scalable foundations that enable these agentic capabilities.\n",
       "- These trends are distinct but deeply synergistic; agent breakthroughs drive and embody ML frontiers, while ML innovations extend agent power and scope.\n",
       "\n",
       "---\n",
       "\n",
       "## References\n",
       "\n",
       "- [IEEE Computer Society, 2025](https://www.computer.org/publications/tech-news/community-voices/autonomous-ai-agents)\n",
       "- [Arxiv, 2025](https://arxiv.org/abs/2501.11739)\n",
       "- [ScienceDaily, 2025](https://www.sciencedaily.com/releases/2025/04/250422131924.htm)\n",
       "- [Phys.org, 2025](https://phys.org/news/2025-04-ai-extrapolative-master-materials.html)\n",
       "- [Medium, 2025](https://medium.com/@taiwo.omotayo/the-cutting-edge-of-machine-learning-whats-new-in-2025-b12fc61dc862)\n",
       "- [MachineLearningMastery.com, 2025](https://machinelearningmastery.com/5-breakthrough-machine-learning-research-papers-already-in-2025/)\n",
       "- [Forbes, 2025](https://www.forbes.com/sites/solrashidi/2025/02/28/the-5-ai-trends-in-2025-agents-open-source-and-multi-model/)\n",
       "- [ScienceDirect, 2025](https://www.sciencedirect.com/science/article/pii/S2949953425000141)\n",
       "- [LinkedIn, 2025](https://www.linkedin.com/pulse/inside-ai-agents-how-perceive-decide-act-learn-artemakis-artemiou-1nzrf)\n",
       "\n",
       "*Consult the cited links for full technical details or request a deeper supplement on any focus area.*\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Blocking response (default)\n",
    "response = await lumnisai_agent.invoke(\"What are the latest trends in AI agents and machine learning?\", user_id=user_email, show_progress=True)\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 734d003d-71ed-4447-b292-d50467f42429\n",
      "PROCESSING: Starting agent...\n",
      "COMPLETED: Response completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As of the latest report, the current weather in Tokyo, Japan is:\n",
       "\n",
       "- **Temperature:** 56°F (13°C)\n",
       "- **Conditions:** Sunny\n",
       "- **Humidity:** 73%\n",
       "- **Wind:** Light, with gusts up to 4 mph\n",
       "- **Visibility:** 7 miles\n",
       "- **Dew Point:** 43°F\n",
       "- **Atmospheric Pressure:** 29.98 inHg\n",
       "\n",
       "Today, the high is forecasted to reach 61°F, with generally sunny weather and a few clouds.\n",
       "\n",
       "For updated details, visit: [Weather Underground - Tokyo, Japan](https://www.wunderground.com/weather/jp/tokyo)  \n",
       "_Source: Weather Underground, updated June 28, 2025_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_scoped_client = lumnisai.AsyncClient().for_user(\"alice@test-acme.one\")\n",
    "response = await user_scoped_client.invoke(\n",
    "    prompt=\"What is the weather in Tokyo?\",\n",
    "    show_progress=True\n",
    ")\n",
    "# print(response.progress)\n",
    "display_markdown(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 9f8f8bb6-6588-4e11-b874-0c9da6e8773e\n",
      "PROCESSING: Starting agent...\n",
      "PROCESSING: Research the most recent (2024-2025) trends in AI agents, referencing reputable sources like academic papers, blogs, and news.\n",
      "PROCESSING: Research the most recent (2024-2025) trends in machine learning, providing relevant references from academic and reputable industry sources.\n",
      "PROCESSING: Analyze and synthesize the latest trends in AI agents and machine learning (2024-2025), highlighting overlaps, unique developments, and emerging directions, with specific references.\n",
      "PROCESSING: Write a comprehensive report (with executive summary, detailed trends, synthesis, and references) on the latest (2024-2025) trends in AI agents and machine learning.\n",
      "PROCESSING: Send a notification message to stakeholders to inform them the AI agents and machine learning trends report is finished, including the report content or a link to it.\n",
      "COMPLETED: Response completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Report: Latest Trends in AI Agents and Machine Learning (2024–2025)\n",
       "\n",
       "---\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "AI agents and machine learning (ML) are converging to power autonomous, adaptable, and collaborative digital intelligence. In 2025, AI agents are widely deployed across industries, leveraging breakthroughs in multimodal, generative models. ML fuels this ecosystem with scalable, explainable, and privacy-preserving approaches. Key trends include explosive adoption, advances in autonomy and multimodality, democratization via no-code/low-code tools, human-centered design, and the active emergence of standards for reliability and governance.\n",
       "\n",
       "---\n",
       "\n",
       "## 1. AI Agents: Key Trends\n",
       "- **Mainstream Deployment:** Over 99% of enterprise developers use or explore AI agents across core business functions (finance, healthcare, supply chain, customer service). Market projected to reach $7.92B in 2025 and $236B by 2034.  \n",
       "  *[IBM, Precedence Research, Master of Code]*\n",
       "- **Complex, Autonomous, Multi-Agent Systems:** Agents now coordinate with each other using new agent-to-agent protocols (A2A, MCP) and orchestrate multifaceted workflows.  \n",
       "  *[Capgemini, MIT TechReview]*\n",
       "- **Next-Gen Platforms:** Major tech players have released agent SDKs and marketplaces (Microsoft Agent Store, Google Gemini Console, AWS, Salesforce, Nvidia).  \n",
       "  *[CRN, Daily AI Agent News]*\n",
       "- **Multimodal & Embodied Agents:** Agents process and act on text, vision, speech, and physical environments (e.g., GPT-4o, Gemini, Nvidia Eureka).  \n",
       "  *[MIT TechReview, Medium]*\n",
       "- **Human-Augmentation:** Copilot-style agents thrive, especially where safety, compliance, or regulation is key.  \n",
       "  *[IBM]*\n",
       "- **Challenges:** Reliability, security, privacy, and energy demands are leading concerns.  \n",
       "  *[LangChain Survey, MIT TechReview, Deloitte]*\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Machine Learning: Key Trends\n",
       "- **Generative & Multimodal Models:** Foundation models (GPT-4o, Gemini, LLaMA) integrate text, image, video, and audio, boosting agentic and general ML use-cases.  \n",
       "  *[Machine Learning Mastery, LinkedIn]*\n",
       "- **Autonomous/Agentic AI:** ML drives ever more capable software agents via advances in reinforcement learning, large context, and self-supervision.  \n",
       "  *[Machine Learning Mastery, Medium]*\n",
       "- **Explainable, Ethical, and Responsible AI:** Growing demand for fairness, transparency, and compliance in ML, supported by regulatory moves in healthcare, finance, and law.  \n",
       "  *[GeeksforGeeks, Medium]*\n",
       "- **Federated & Edge ML:** Privacy-preserving, decentralized deployment of ML models, vital for sensitive industries like healthcare, IoT, and finance.  \n",
       "  *[Medium, GeeksforGeeks]*\n",
       "- **Data-Centric AI:** Synthetic datasets, AutoML tools, and low-code/no-code platforms lower barriers for non-experts.  \n",
       "  *[Medium, LinkedIn]*\n",
       "- **Quantum and Causal ML:** Early-stage hybrid quantum-classical and causal inference techniques are emerging.  \n",
       "  *[LinkedIn, Medium]*\n",
       "- **Real-Time/Continual Learning:** Models adapt in real-time from streaming data, powering dynamic business and industrial apps.  \n",
       "  *[Medium, LinkedIn]*\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Synthesis & Comparative Analysis\n",
       "\n",
       "### Overlapping Trends\n",
       "- **Autonomy & Collaboration:** Both fields are rapidly converging on self-directed, context-adaptive, multi-agent architectures.\n",
       "- **Multimodality & Generativity:** Foundation models empower agents with broad, generative abilities across data types.\n",
       "- **Democratization:** Low-code/no-code platforms and marketplaces drive use by domain experts and non-coders.\n",
       "- **Human-centered, Responsible Intelligence:** Emphasis on human oversight, safety, reliability, and auditability.\n",
       "- **Common Challenges:** Both struggle with output honesty (hallucinations), compliance, privacy, and energy impact.\n",
       "\n",
       "### Unique Developments\n",
       "- **AI Agents:** Focus on workflow automation, agent-to-agent protocols, and agent application marketplaces.\n",
       "- **Machine Learning:** Advances in foundation models (>10T parameters), continual/self-supervised learning, and novel hardware.\n",
       "\n",
       "### Emerging Directions\n",
       "- Continual-learning and end-to-end differentiable agent architectures.\n",
       "- Standardization enabling ML models and agents to interoperate seamlessly.\n",
       "- \"Ethical agent\" frameworks for transparency, fairness, and accountability.\n",
       "\n",
       "---\n",
       "\n",
       "## Reference List\n",
       "\n",
       "1. [IBM: AI Agents in 2025—Expectations vs. Reality](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality)\n",
       "2. [Precedence Research: AI Agents Market Size Worth USD 236B by 2034](https://www.globenewswire.com/news-release/2025/07/02/3109307/0/en/AI-Agents-Market-Size-Worth-USD-236-03-Billion-by-2034-Fueled-by-Machine-Learning-and-Natural-Language-Processing-Advances.html)\n",
       "3. [Master of Code: 150+ AI Agent Statistics (July 2025)](https://masterofcode.com/blog/ai-agent-statistics)\n",
       "4. [Capgemini/CNBC: AI Agent Collaboration in 2025](https://www.cnbc.com/2024/07/22/ai-that-can-talk-with-other-ai-will-launch-in-2025-capgemini-predicts.html)\n",
       "5. [MIT Technology Review: What are AI agents? (July 2024)](https://www.technologyreview.com/2024/07/05/1094711/what-are-ai-agents/)\n",
       "6. [CRN: 10 Hottest Agentic AI Tools Of 2025](https://www.crn.com/news/ai/2025/10-hottest-agentic-ai-tools-and-agents-of-2025-so-far)\n",
       "7. [AI Agent Store: Daily AI Agent News, May 2025](https://aiagentstore.ai/ai-agent-news/2025-may)\n",
       "8. [Medium (Edwin Lisowski): AI Agents Take the Lead: 2025](https://medium.com/@elisowski/a-list-of-ai-agents-set-to-dominate-in-2025-028f975c5b99)\n",
       "9. [Deloitte: TMT 2025 Predictions](https://www2.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2025/autonomous-generative-ai-agents-still-under-development.html)\n",
       "10. [Machine Learning Mastery - 7 Machine Learning Trends to Watch in 2025](https://machinelearningmastery.com/7-machine-learning-trends-2025/)\n",
       "...and more listed in the detailed findings section.\n",
       "\n",
       "---\n",
       "\n",
       "**For further detail, see referenced academic articles and industry reports. The convergence of AI agents and ML is defining the new era of adaptive, intelligent digital systems across the global economy.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await user_scoped_client.invoke(\n",
    "    prompt=\"What are the latest trends in AI agents and machine learning? \",\n",
    "    show_progress=True\n",
    "    )\n",
    "# print(response.progress)\n",
    "display_markdown(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0 templates\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
