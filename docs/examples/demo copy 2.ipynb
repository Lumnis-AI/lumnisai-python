{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lumnisai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Users:\n",
      "     lumnistrading@gmail.com 8f99e82d-ca41-4e51-84c8-54eee4588d68\n",
      "     peytonjohnson710@gmail.com f065a840-2005-4181-93d7-40544666cafd\n",
      "     kabirjaiswal30@gmail.com 559a7a0c-e1fc-4a44-80e3-e9e1ef8fff2f\n",
      "     aakash@secondaxis.ai 5f55ac40-841e-4c53-832e-d21b2e6f313e\n",
      "     ajaye12@illinois.edu a312cf13-0693-4713-9433-4c139b0da185\n",
      "     moribajaye@gmail.com 8fc1a34c-b335-4f03-a25c-8dadba04dab1\n",
      "     ajaye2@illinois.edu 4bd0c7f3-9f13-481d-a673-6a03c8945c6c\n",
      "     abujaye@gmail.com b33224a4-8700-4427-be85-7baedacd0115\n",
      "     mosompo08@gmail.com ab778a36-4cc0-4aa3-9ac7-087307395e5a\n",
      "     mikeszczerba0@gmail.com a9625b3c-c4a1-4b82-addf-2b0c7c3942be\n",
      "     alice@test-acme.one 8d5627e1-4f66-4676-99bf-3d5bedcd45f4\n",
      "==================================================\n",
      "Existing API keys:\n",
      "     E2B_API_KEY Exists - Created at 2025-09-04T02:48:00.873043+00:00\n",
      "     EXA_API_KEY Exists - Created at 2025-08-17T19:19:54.791579+00:00\n",
      "     OPENAI_API_KEY Exists - Created at 2025-08-17T19:19:50.588078+00:00\n",
      "==================================================\n",
      "Model Preferences (Tenant: 7ed13659-53d8-428d-b86b-566790261c94):\n",
      "  CHEAP_MODEL: openai:gpt-4.1-nano ✓\n",
      "  FAST_MODEL: openai:gpt-4.1-mini ✓\n",
      "  SMART_MODEL: openai:gpt-4.1 ✓\n",
      "  REASONING_MODEL: openai:o3 ✓\n",
      "  VISION_MODEL: openai:gpt-4.1-mini ✓\n",
      "\n",
      "Defaults applied for: CHEAP_MODEL, VISION_MODEL\n",
      "==================================================\n",
      "User Connections (User ID: abujaye@gmail.com):\n",
      "  OUTLOOK: active (connected: 2025-09-07 18:54:41.193609)\n",
      "  GOOGLEDRIVE: active (connected: 2025-09-07 18:54:40.668846)\n",
      "  NOTION: pending\n",
      "  GOOGLESHEETS: active (connected: 2025-09-07 18:54:40.035127)\n",
      "  GOOGLEDOCS: active (connected: 2025-09-07 18:54:39.316557)\n",
      "  SLACK: pending\n",
      "  GITHUB: active (connected: 2025-09-07 18:54:37.863865)\n",
      "  GMAIL: active (connected: 2025-09-07 18:54:38.721172)\n",
      "\n",
      "Total connections: 8\n",
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "\n",
    "import lumnisai\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def display_markdown(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "# Create client\n",
    "lumnisai_agent = lumnisai.AsyncClient()\n",
    "\n",
    "# List users\n",
    "users = await lumnisai_agent.list_users(page_size=50)\n",
    "\n",
    "# Check if alice@test-acme.one exists in users\n",
    "alice_user = next((user for user in users.users if user.email == \"alice@test-acme.one\"), None)\n",
    "\n",
    "# Create user if not found\n",
    "if alice_user is None:\n",
    "    user = await lumnisai_agent.create_user( email=\"alice@test-acme.one\", first_name=\"Alice\", last_name=\"Doe\" )\n",
    "\n",
    "# Print users\n",
    "print(\"Existing Users:\")\n",
    "for user in users.users:\n",
    "    print(\"    \", user.email, user.id)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# List API keys\n",
    "api_keys = await lumnisai_agent.list_api_keys()\n",
    "print(\"Existing API keys:\")\n",
    "for api_key in api_keys:\n",
    "    print(\"    \", api_key.provider, \"Exists - Created at\", api_key.created_at)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add API keys\n",
    "await lumnisai_agent.add_api_key(lumnisai.ApiProvider.OPENAI_API_KEY, os.getenv(\"OPENAI_API_KEY\"))\n",
    "await lumnisai_agent.add_api_key(lumnisai.ApiProvider.EXA_API_KEY, os.getenv(\"EXA_API_KEY\"))\n",
    "\n",
    "preferences = await lumnisai_agent.get_model_preferences()\n",
    "print(preferences)\n",
    "\n",
    "user_email = \"abujaye@gmail.com\" \n",
    "\n",
    "# List connections\n",
    "print(\"=\"*50)\n",
    "connections = await lumnisai_agent.list_connections(user_email)\n",
    "print(connections)\n",
    "\n",
    "# # List tools\n",
    "# print(\"=\"*50)\n",
    "# tools = await lumnisai_agent.get_integration_tools(user_email)\n",
    "# print(tools)\n",
    "\n",
    "# new_preferences = {\n",
    "#     \"FAST_MODEL\": {\n",
    "#         \"provider\": \"openai\",\n",
    "#         \"model_name\": \"gpt-4.1-mini\"\n",
    "#     },\n",
    "#     \"SMART_MODEL\": {\n",
    "#         \"provider\": \"openai\",\n",
    "#         \"model_name\": \"gpt-4.1\"\n",
    "#     },\n",
    "#     \"REASONING_MODEL\": {\n",
    "#         \"provider\": \"openai\",\n",
    "#         \"model_name\": \"o3\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# updated = await lumnisai_agent.update_model_preferences(new_preferences)\n",
    "# print(updated)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supabase MCP server already exists: Supabase-mcp-server\n"
     ]
    }
   ],
   "source": [
    "mcp_serrver_name = \"Supabase-mcp-server\"\n",
    "\n",
    "mcp_servers = await lumnisai_agent.list_mcp_servers()\n",
    "supabase_server_exists = next((server for server in mcp_servers.servers if server.name == \"Supabase-mcp-server\"), None)\n",
    "\n",
    "if supabase_server_exists is None:\n",
    "    supabase_server = await lumnisai_agent.create_mcp_server(\n",
    "        name=f\"Supabase-mcp-server\",\n",
    "        transport=\"stdio\",\n",
    "        scope=\"user\",\n",
    "        user_identifier=user_email,\n",
    "        description=\"Supabase\",\n",
    "        command=\"npx\",\n",
    "        args=[\"-y\", \"@supabase/mcp-server-supabase@latest\", \"--project-ref=rcxermhxsgrxyfvpozcb\"],\n",
    "        env={\n",
    "            \"SUPABASE_ACCESS_TOKEN\": os.environ.get(\"SUPABASE_ACCESS_TOKEN\"),\n",
    "        },\n",
    "    )\n",
    "    print(f\"Supabase MCP server created: {supabase_server.name}\")\n",
    "else:\n",
    "    print(f\"Supabase MCP server already exists: {supabase_server_exists.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 5d78192b-fb46-4080-a131-95509ccbc608\n",
      "PROCESSING - Agent thinking...\n",
      "PROCESSING - Analyzing request and planning approach...\n",
      "PROCESSING - Research the latest (2024-2025) trends in AI agents and machine learning, define agentic models, find 5-8 recent key papers, and write a concise summary with subject line and reference list.\n",
      "PROCESSING - Compose and send an email with the research summary, subject line, and references to moriba.jaye@gmail.com.\n",
      "COMPLETED - Response completed successfully.\n",
      "COMPLETED - Task completed successfully\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The research summary and full list of references have been emailed to moriba.jaye@gmail.com under the subject line:\n",
       "\n",
       "“2025 Snapshot: Key Trends & Papers Driving Agentic AI”\n",
       "\n",
       "Let me know if any follow-up or additional details are needed!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "--------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Streaming response  \n",
    "async for update in await lumnisai_agent.invoke(\"\"\" \n",
    "                                                What are the latest trends in AI agents and machine learning? \n",
    "                                                What are agentic models? \n",
    "                                                What are the latest papers on agentic models and agentic AI?. \n",
    "                                                Send email to moriba.jaye@gmail.com.\n",
    "                                                \"\"\", stream=True, user_id=user_email):\n",
    "    print(f\"{update.state.upper()} - {update.message}\")\n",
    "\n",
    "display(Markdown(update.output_text))\n",
    "display(Markdown(\"--------------------------------\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: cbfb223e-d94b-4f48-a066-7e32a859ad04\n",
      "PROCESSING - Agent thinking...\n",
      "PROCESSING - Analyzing request and planning approach...\n",
      "PROCESSING - Connecting to the rcxermhxsgrxyfvpozcb database to list all available schemas with descriptions.\n",
      "PROCESSING - Querying the public.temp and public.colors tables: returning complete data, metadata, and analysis.\n",
      "COMPLETED - Response completed successfully.\n",
      "COMPLETED - Task completed successfully\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Schema inventory (project `rcxermhxsgrxyfvpozcb`)**\n",
       "\n",
       "| # | Schema | Description (purpose / typical contents) |\n",
       "|---|--------|-------------------------------------------|\n",
       "| 1 | auth | Supabase Auth tables (users, sessions, tokens) |\n",
       "| 2 | extensions | Metadata for installed PostgreSQL extensions |\n",
       "| 3 | graphql | Supabase GraphQL-engine internals |\n",
       "| 4 | graphql_public | Auto-generated, read-only GraphQL views |\n",
       "| 5 | information_schema | ANSI-standard catalog views |\n",
       "| 6 | pg_catalog | Core PostgreSQL system catalog |\n",
       "| 7 | pg_temp … | Session-local temporary schema |\n",
       "| 8 | pg_toast | Storage for out-of-line large values |\n",
       "| 9 | pg_toast_temp … | TOAST companion for temp schema |\n",
       "|10 | pgbouncer | PgBouncer stats / settings |\n",
       "|11 | public | Default user/application tables |\n",
       "|12 | realtime | Supabase Realtime metadata |\n",
       "|13 | storage | Supabase Storage backing tables |\n",
       "|14 | vault | Supabase Vault (secrets management) |\n",
       "\n",
       "---\n",
       "\n",
       "### Table `public.temp`\n",
       "\n",
       "| Column | Type | Null? | Default | Notes |\n",
       "|--------|------|-------|---------|-------|\n",
       "| id | bigint | NO | — | **PK**, indexed (`temp_pkey`) |\n",
       "| created_at | timestamptz | NO | `now()` | creation timestamp |\n",
       "| abu | text | YES | — | free-text |\n",
       "\n",
       "• Indexes/constraints: primary-key index on `id`; no FKs, uniques or triggers  \n",
       "• Row count: **2**\n",
       "\n",
       "| id   | created_at (UTC)             | abu  |\n",
       "|------|------------------------------|------|\n",
       "| 232 322 | 2025-09-07 03:24:33.044433 | 2432 |\n",
       "| 23     | 2025-09-07 03:24:38.723035 | dfdf |\n",
       "\n",
       "_Notable points_: test/scratch table; non-sequential IDs; no NULLs yet.\n",
       "\n",
       "---\n",
       "\n",
       "### Table `public.colors`  (rows where `name` starts with “A”)\n",
       "\n",
       "| Column | Type | Null? | Notes |\n",
       "|--------|------|-------|-------|\n",
       "| id | bigint | NO | **PK** |\n",
       "| name | text | YES | — |\n",
       "| hex | text | NO | six-digit hex (with “#”) |\n",
       "| red / green / blue | smallint | YES | 0-100 intensity |\n",
       "| hue | smallint | YES | 0-360° |\n",
       "| sat_hsl / light_hsl | smallint | YES | 0-100 |\n",
       "| sat_hsv / val_hsv | smallint | YES | 0-100 |\n",
       "| source | enum(source) | YES | origin category |\n",
       "\n",
       "Indexes/constraints: primary-key index on `id`; no other indexes or triggers.\n",
       "\n",
       "Filtered result: **32 rows** (complete dataset included; excerpt below).\n",
       "\n",
       "| id | name            | hex     | R | G | B | hue | sat_hsl | light_hsl | sat_hsv | val_hsv | source |\n",
       "|----|-----------------|---------|---|---|---|-----|---------|-----------|---------|---------|--------|\n",
       "| 1 | Absolute Zero    | #0048BA | 0 | 28 | 73 | 217 | 100 | 37 | 100 | 73 | CRAYOLA |\n",
       "| 2 | Acid green       | #B0BF1A | 69 | 75 | 10 | 65 | 76 | 43 | 76 | 75 | ART_PAINTS_YG07S |\n",
       "| 3 | Aero             | #7CB9E8 | 49 | 73 | 91 | 206 | 70 | 70 | 47 | 91 | X11_WEB |\n",
       "| … | … (29 more) | | | | | | | | | |\n",
       "\n",
       "_Observations_\n",
       "\n",
       "• No NULLs in numeric columns for this subset.  \n",
       "• `sat_hsv` values cluster at very high (≥ 92) or very low (≤ 18) saturation → vivid vs. pastel.  \n",
       "• IDs & names unique; consider adding a case-insensitive **UNIQUE** constraint on `name`.  \n",
       "• Only primary-key indexing; optionally add functional index `lower(name)` for faster look-ups.\n",
       "\n",
       "---\n",
       "\n",
       "**Key take-aways**\n",
       "\n",
       "1. Both tables are simple, with only primary-key indexes and no triggers or FKs.  \n",
       "2. `public.temp` is tiny scratch data; `public.colors` is well-structured reference data.  \n",
       "3. No sensitive information present; low privacy risk.  \n",
       "4. Potential improvements: unique/index on `colors.name`, additional analytic indexes if queries grow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = \"\"\"\n",
    "List tables in the --project-ref=rcxermhxsgrxyfvpozcb project.\n",
    "\n",
    "There is a table called \"colors\" in the public schema.\n",
    "\n",
    "Step 1.: Start by listing all available schemas\n",
    "Step 2.: Then get all colors that start with \"A\"\n",
    "Step 3.: Return the columns and rows from the table and lest any interesting information.\n",
    "\"\"\"\n",
    "\n",
    "async for update in await lumnisai_agent.invoke(task, stream=True, user_id=user_email):\n",
    "    print(f\"{update.state.upper()} - {update.message}\")\n",
    "\n",
    "display(Markdown(update.output_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 5d9c1ce7-ed6a-4ce8-9bd0-77580a06575b\n",
      "PROCESSING - Agent thinking...\n",
      "PROCESSING - Analyzing request and planning approach...\n",
      "PROCESSING - Locate the '9,000+ Investors' spreadsheet, verify it contains investor data, and provide metadata including URL, ID, sheet names, headers, row/column counts, and sample rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = \"\"\"\n",
    "Read the top 1000 rows of the 9,000+ Investors spreadsheet and identify which ones would be good for Lumnis AI? We're building an API platform for AI agents and looking for pre-seed/incubator stage investors.\n",
    "\n",
    "The name of the spreadsheet is \"9,000+ Investors\".\n",
    "\"\"\"\n",
    "\n",
    "async for update in await lumnisai_agent.invoke(task, stream=True, user_id=user_email):\n",
    "    print(f\"{update.state.upper()} - {update.message}\")\n",
    "\n",
    "display(Markdown(update.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: 092be959-a59a-4af8-84a9-c87a808eba6f\n",
      "PROCESSING: Agent thinking...\n",
      "PROCESSING: Analyzing request and planning approach...\n",
      "PROCESSING: Gather and compile verified business information (address, phone, website, category, ratings, hours) for the Louvre Museum using authoritative sources.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example demonstrating how to use structured output with the Lumnis SDK.\n",
    "\n",
    "The SDK supports two ways to specify response format:\n",
    "1. Pass a Pydantic model class directly (recommended)\n",
    "2. Pass a JSON Schema dictionary\n",
    "\"\"\"\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: Optional[str] = None\n",
    "\n",
    "class BusinessInfo(BaseModel):\n",
    "    name: str = Field(description=\"Business name\")\n",
    "    category: str = Field(description=\"Type of business\")\n",
    "    address: Address\n",
    "    phone: Optional[str] = None\n",
    "    website: Optional[str] = None\n",
    "    rating: Optional[float] = Field(None, ge=0, le=5)\n",
    "\n",
    "\n",
    "# Example: Complex structure with nested models\n",
    "response_structured = await lumnisai_agent.invoke(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me about the Louvre Museum. Get the address, and as much business information as possible (e.g. category, phone, website, rating).\"}],\n",
    "    response_format=BusinessInfo,  # Pass the model class directly\n",
    "    response_format_instructions=\"Include all available details\",\n",
    "    user_id=user_email\n",
    ")\n",
    "\n",
    "if response_structured.structured_response:\n",
    "    museum = BusinessInfo(**response_structured.structured_response)\n",
    "    print(f\"Museum: {museum.name}\")\n",
    "    print(f\"Location: {museum.address.city}, {museum.address.country}\")\n",
    "\n",
    "    print(json.dumps(response_structured.structured_response, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: a57676d3-8313-4a19-bddf-c161d5fbea4f\n",
      "PROCESSING - Agent thinking...\n",
      "PROCESSING - Analyzing request and planning approach...\n",
      "PROCESSING - Summarize 2023-2024 peer-reviewed literature on new diagnostic methods and treatments for Alzheimer's disease.\n",
      "PROCESSING - Interpret clinical significance of summarized Alzheimer’s diagnostic and treatment advances and list gaps.\n",
      "PROCESSING - Analyze clinical significance of summarized Alzheimer’s advances and identify practice gaps.\n",
      "PROCESSING - Draft grant proposal outline addressing identified Alzheimer’s research gaps.\n",
      "COMPLETED - Response completed successfully.\n",
      "COMPLETED - Task completed successfully\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Data Analyst Section – 2023-2024 Research Summary**\n",
       "\n",
       "**Diagnostic advances**  \n",
       "• Blood biomarkers: plasma p-tau 181/217, GFAP, and NfL consistently show AUC ≥ 0.90 for early AD detection; likely to become front-line screens.  \n",
       "• AI-enhanced multimodal imaging: CNN/transformer models combining MRI ± PET reach AUC 0.93–0.98 for AD/MCI classification but lack external validation.  \n",
       "• Retinal OCT/OCT-A biomarkers: nerve-fiber-layer thinning and foveal-avascular-zone changes correlate with amyloid status, offering a cheap, non-invasive screen.  \n",
       "• 2024 NIA-AA framework: biologic definition of AD using Core-1 biomarkers (Aβ + p-tau) and four biologic stages, promoting biomarker-confirmed diagnosis.  \n",
       "\n",
       "**Treatment advances**  \n",
       "• Lecanemab (FDA approved 2023): 27 % slower decline on CDR-SB; ARIA ≈ 13 %.  \n",
       "• Donanemab (regulatory review 2024): 35 % slowing; greater benefit in low/intermediate tau; ARIA ≈ 26 %.  \n",
       "• Next-generation agents: remternetug (faster amyloid clearance), oral ALZ-801 (p-tau↓ 31 %), and BIIB080 antisense (CSF tau↓ 50-65 %) signal shift toward combination or sequential amyloid- and tau-targeted therapy.  \n",
       "\n",
       "*(14 key studies; methods: PubMed/Scopus/Web of Science search Jan 2023–Sep 2024; prioritized systematic reviews and phase-2/3 RCTs.)*\n",
       "\n",
       "---\n",
       "\n",
       "**Medical Expert Section – Clinical Interpretation & Gaps**\n",
       "\n",
       "Clinical significance  \n",
       "• Blood-first algorithms followed by confirmatory PET/CSF can reduce time-to-diagnosis and widen access.  \n",
       "• Amyloid mAbs confirm disease-modifying era but provide modest benefit and require MRI monitoring for ARIA; biomarker-guided selection (amyloid+, intermediate tau, APOE ε4 status) is essential.  \n",
       "• Sequential amyloid-then-tau therapy is biologically plausible yet untested.  \n",
       "\n",
       "Key barriers  \n",
       "1. Lack of multi-ethnic external validation for AI and blood assays.  \n",
       "2. High drug cost and ARIA management limit community adoption.  \n",
       "3. Insufficient long-term (> 5 yr) functional-outcome data.  \n",
       "4. Under-representation of minority populations in trials.  \n",
       "5. Unstandardized retinal imaging protocols.  \n",
       "\n",
       "Prioritised gaps  \n",
       "1. External validation of blood/AI algorithms.  \n",
       "2. Head-to-head biomarker-guided DMT trials.  \n",
       "3. ARIA-mitigation registries in APOE ε4 carriers.  \n",
       "4. Sequential/combination amyloid → tau therapy trials.  \n",
       "5. Cost-effectiveness of blood-first screening.  \n",
       "6. Retinal biomarker standardisation.  \n",
       "7. Inclusive, long-term outcome cohorts.\n",
       "\n",
       "---\n",
       "\n",
       "**Grant Writer Section – Proposal Outline**\n",
       "\n",
       "**Title**  \n",
       "Precision Alzheimer’s Initiative (PAI): Integrating Blood Biomarkers, Explainable AI Imaging, and Sequential Amyloid-Tau Therapeutics\n",
       "\n",
       "**Background & Significance**  \n",
       "Breakthroughs in blood biomarkers and DMTs expose four urgent gaps: scalable, validated diagnosis; equitable data; optimisation of DMT sequencing; and infrastructure for combination regimens.\n",
       "\n",
       "**Specific Aims**  \n",
       "1. Validate a blood-first (p-tau217 + GFAP) diagnostic algorithm in a diverse 2 000-person cohort.  \n",
       "2. Develop and externally validate an explainable 3D-CNN + transformer imaging model.  \n",
       "3. Test sequential lecanemab → BIIB080 versus lecanemab alone in an adaptive 300-patient trial.  \n",
       "4. Build a FAIR, multi-ethnic AD biomarker-imaging-genomic data commons (n = 5 000).\n",
       "\n",
       "**Methods/Approach**  \n",
       "• Community recruitment (≥ 40 % non-White).  \n",
       "• Standardised mass-spec plasma assays; 3 T MRI ± amyloid/tau-PET.  \n",
       "• Federated learning for AI; SHAP saliency for interpretability.  \n",
       "• Bayesian adaptive trial with ARIA-risk-based dosing adjustments.  \n",
       "• Cloud-based data platform with patient-advocate governance.\n",
       "\n",
       "**Expected Impact**  \n",
       "• Regulatory-ready, low-cost diagnostic workflow.  \n",
       "• Evidence for superior cognitive benefit of sequential amyloid-tau therapy.  \n",
       "• Inclusive dataset to minimise algorithmic bias.\n",
       "\n",
       "**Innovation**  \n",
       "First integration of scalable blood tests, explainable AI imaging, and adaptive sequential DMT trial, paired with an open, representative data commons.\n",
       "\n",
       "**Recommended Next Steps**  \n",
       "1. Pilot plasma-assay variability study (n = 50).  \n",
       "2. Formalise reagent and drug partnerships (assay vendors; Biogen/Eisai; Ionis/Lilly).  \n",
       "3. Pre-IND meeting with FDA; secure IRB approval focusing on diversity.  \n",
       "4. Draft NIH (NIA) and Alzheimer’s Association grant applications.  \n",
       "5. Establish advisory board (biostatistics, neuroethics, patient advocates).  \n",
       "6. Develop data-governance & consent framework per NIH DMS policy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Multi-agent collaboration for a complex research task\n",
    "\n",
    "# Define a scenario where multiple specialized agents collaborate:\n",
    "# - A Data Analyst agent to summarize recent research papers on Alzheimer's disease\n",
    "# - A Medical Expert agent to interpret findings and suggest clinical implications\n",
    "# - A Grant Writer agent to draft a funding proposal based on the findings\n",
    "\n",
    "multi_agent_prompt = (\n",
    "    \"You are coordinating a team of three AI agents:\\n\"\n",
    "    \"1. Data Analyst: Summarize the latest (2023-2024) peer-reviewed research on Alzheimer's disease, focusing on new diagnostic methods and treatments.\\n\"\n",
    "    \"2. Medical Expert: Interpret the summarized findings, discuss their clinical significance, and identify gaps in current practice.\\n\"\n",
    "    \"3. Grant Writer: Using the above, draft a compelling outline for a research grant proposal to address the identified gaps.\\n\"\n",
    "    \"Each agent should contribute their section clearly labeled. Conclude with a list of recommended next steps for the research team.\"\n",
    ")\n",
    "\n",
    "async for update in await lumnisai_agent.invoke(multi_agent_prompt, user_id=user_email, stream=True):\n",
    "    print(f\"{update.state.upper()} - {update.message}\")\n",
    "\n",
    "display_markdown(update.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
